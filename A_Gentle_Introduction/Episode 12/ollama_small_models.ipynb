{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1397e31a-d421-40ea-b822-c28ba0a94fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b82956b-ed93-4ce6-98c0-24b3bacab4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import list, generate\n",
    "from ollama import ListResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52470549-56e7-4b10-b7c7-cdc4880df566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of models from the local Ollama instance\n",
    "# NOTE: This code assumes Ollama is running and accessible.\n",
    "list_response: ListResponse = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d13e6d-3243-438c-9c28-790f286b003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list to store the models\n",
    "models_to_test = []\n",
    "\n",
    "for model in list_response.models:\n",
    "  models_to_test.append(model.model)\n",
    "  print('Name:', model.model)\n",
    "  print('  Size (MB):', f'{(model.size.real / 1024 / 1024):.2f}')\n",
    "  if model.details:\n",
    "    print('  Format:', model.details.format)\n",
    "    print('  Family:', model.details.family)\n",
    "    print('  Parameter Size:', model.details.parameter_size)\n",
    "    print('  Quantization Level:', model.details.quantization_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5cc468-7f33-459f-8ad5-629344e33aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the list of models found\n",
    "if models_to_test:\n",
    "    print(\"Found the following models:\")\n",
    "    for model_name in models_to_test:\n",
    "        print(f\"- {model_name}\")\n",
    "else:\n",
    "    print(\"No models found in the provided list.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d744e590-d4b1-4409-9798-d324a1b4ab56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Basic Text Generation\n",
    "print(\"--- Basic Text Generation ---\")\n",
    "prompt_generation = \"Write a short poem about a cat.\"\n",
    "for model_name in models_to_test:\n",
    "    try:\n",
    "        response = generate(model=model_name, prompt=prompt_generation)\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "        print(\"-\" * 20)\n",
    "        print(response['response'])\n",
    "        print(\"-\" * 20)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError with model {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731835e6-6879-42b4-bc3d-a747aab7c549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Instruction Following\n",
    "print(\"\\n--- Instruction Following ---\")\n",
    "prompt_instruction = \"Summarize the following text in one sentence: 'The concept of photosynthesis, the process by which plants convert light energy into chemical energy, is fundamental to life on Earth. It involves the absorption of carbon dioxide from the atmosphere and the release of oxygen. The process is crucial for both plant growth and the global carbon cycle.'\"\n",
    "for model_name in models_to_test:\n",
    "    try:\n",
    "        response = generate(model=model_name, prompt=prompt_instruction)\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "        print(\"-\" * 20)\n",
    "        print(response['response'])\n",
    "        print(\"-\" * 20)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError with model {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c260b5bf-fee9-468e-a6dc-e3e8ffb3f144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Question Answering\n",
    "print(\"\\n--- Question Answering ---\")\n",
    "question = \"What is the capital of France?\"\n",
    "for model_name in models_to_test:\n",
    "    try:\n",
    "        response = generate(model=model_name, prompt=question)\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "        print(\"-\" * 20)\n",
    "        print(response['response'])\n",
    "        print(\"-\" * 20)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError with model {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acae201-e3bb-4f76-b30c-431157140694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.Code generation \n",
    "print(\"\\n--- Code generation ---\")\n",
    "code_request = \"Generate Python code that: 'Given two sorted arrays nums1 and nums2 of size m and n respectively, return the median of the two sorted arrays.'\"\n",
    "for model_name in models_to_test:\n",
    "    try:\n",
    "        response = generate(model=model_name, prompt=code_request)\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "        print(\"-\" * 20)\n",
    "        print(response['response'])\n",
    "        print(\"-\" * 20)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError with model {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9935b67-cae8-49b8-819f-165d57a9636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Technical Question Answering\n",
    "print(\"\\n--- Technical Question Answering ---\")\n",
    "technical_question = \"What is Mixture of Experts?\"\n",
    "for model_name in models_to_test:\n",
    "    try:\n",
    "        response = generate(model=model_name, prompt=technical_question)\n",
    "        print(f\"\\nModel: {model_name}\")\n",
    "        print(\"-\" * 20)\n",
    "        print(response['response'])\n",
    "        print(\"-\" * 20)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError with model {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1c0a01-e70f-4c66-8b08-5b2eff4684d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Technical Question Answering - Increasing Temperature\n",
    "print(\"\\n--- Technical Question Answering with Increasing Temperature ---\")\n",
    "technical_question = \"What is Mixture of Experts?\"\n",
    "model_name = \"qwen2.5:0.5b\"\n",
    "print(f\"\\nModel: {model_name}\")\n",
    "\n",
    "for temperature in [i / 10.0 for i in range(0, 11)]:\n",
    "    print(f\"\\nTemperature: {temperature}\")\n",
    "    model_options = {\"temperature\": temperature}\n",
    "    try:\n",
    "        response = generate(model=model_name, prompt=technical_question, options=model_options)\n",
    "        print(\"-\" * 20)\n",
    "        print(response['response'])\n",
    "        print(\"-\" * 20)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError with model {model_name} at temperature {temperature}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f268c16-b0d0-4426-8405-daf3b759b259",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
