{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e40d51-9638-40c7-95c6-c844970147b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b33ccf2-00bf-4181-ac0d-a38093a725b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_model_if_needed(model_name):\n",
    "    \"\"\"Pulls the specified model from Ollama if it doesn't exist.\"\"\"\n",
    "    try:\n",
    "        ollama.pull(model=model_name)\n",
    "        print(f\"Model '{model_name}' pulled successfully/already existed.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error pulling model '{model_name}': {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b98f05-6d0a-4614-b3b9-a660ed4027f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt(model_name, prompt):\n",
    "    \"\"\"Runs a prompt on a given model and returns the response.\"\"\"\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=model_name,\n",
    "            messages=[{'role': 'user', 'content': prompt}]\n",
    "        )\n",
    "        return response['message']['content'].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error running prompt on model '{model_name}': {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55663344-3492-4749-a612-c988be0f8bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_test = [\"gemma3\", \"llama3.1\"]  # Add more models as desired\n",
    "starting_sentence = \"The old lighthouse keeper, Silas, squinted at the horizon where a storm was brewing faster than any he'd seen in his seventy years.\"\n",
    "story_segment = starting_sentence\n",
    "\n",
    "print(\"--- Creative Writing Partner Experiment in Ollama ---\")\n",
    "print(f\"Starting sentence: {starting_sentence}\\n\")\n",
    "\n",
    "for model_name in models_to_test:\n",
    "    print(f\"\\n--- Model: {model_name} ---\")\n",
    "    if not pull_model_if_needed(model_name):\n",
    "        continue\n",
    "\n",
    "    story_segment = starting_sentence  # Reset for each model\n",
    "\n",
    "    # First continuation\n",
    "    prompt_1 = f\"{story_segment}\\n\\nContinue this story.\"\n",
    "    continuation_1 = run_prompt(model_name, prompt_1)\n",
    "    if continuation_1:\n",
    "        story_segment += \" \" + continuation_1.strip()\n",
    "        print(f\"(Turn 1 - Continuation):\\n{continuation_1}\\n\")\n",
    "\n",
    "        # Second continuation with a twist\n",
    "        prompt_2 = f\"{story_segment}\\n\\nNow, introduce a surprising plot twist.\"\n",
    "        continuation_2 = run_prompt(model_name, prompt_2)\n",
    "        if continuation_2:\n",
    "            story_segment += \" \" + continuation_2.strip()\n",
    "            print(f\"(Turn 2 - Twist):\\n{continuation_2}\\n\")\n",
    "\n",
    "            # Third continuation focusing on character feelings\n",
    "            prompt_3 = f\"{story_segment}\\n\\nDescribe Silas's feelings in more detail after this twist.\"\n",
    "            continuation_3 = run_prompt(model_name, prompt_3)\n",
    "            if continuation_3:\n",
    "                story_segment += \" \" + continuation_3.strip()\n",
    "                print(f\"(Turn 3 - Character Feelings):\\n{continuation_3}\\n\")\n",
    "\n",
    "                print(f\"--- End of Turn 3 for {model_name} - Full Story Segment: ---\\n{story_segment}\\n\")\n",
    "            else:\n",
    "                print(f\"Model {model_name} failed to continue after the twist.\\n\")\n",
    "        else:\n",
    "            print(f\"Model {model_name} failed to introduce a plot twist.\\n\")\n",
    "    else:\n",
    "        print(f\"Model {model_name} failed to provide the initial continuation.\\n\")\n",
    "\n",
    "print(\"\\n--- Observation ---\")\n",
    "print(\"Observe how well each model maintains coherence throughout the story.\")\n",
    "print(\"Note if the models successfully follow the creative instructions (continuation, twist, character feelings).\")\n",
    "print(\"Compare the prose generated by different models. Which one produces more engaging and creative writing?\")\n",
    "print(\"Consider how well the models remember the context from previous turns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7467bc7b-7d48-4e23-b375-a0156b87ad84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392b590e-0be1-46cb-a371-dccbf0e4f7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
