{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf7ae92-572d-4862-a31e-b952dd330b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4816e18a-17a6-4456-b8c2-3986946f7875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_model_if_needed(model_name):\n",
    "    \"\"\"Pulls the specified model from Ollama if it doesn't exist.\"\"\"\n",
    "    try:\n",
    "        ollama.pull(model=model_name)\n",
    "        print(f\"Model '{model_name}' pulled successfully/already existed.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error pulling model '{model_name}': {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d53f1d7-9393-4aae-bd97-95f60fd3d551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_time_prompt(model_name, prompt):\n",
    "    \"\"\"Runs a prompt on a given model and measures the response time.\"\"\"\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=model_name,\n",
    "            messages=[{'role': 'user', 'content': prompt}]\n",
    "        )\n",
    "        end_time = time.time()\n",
    "        response_text = response['message']['content'].strip()\n",
    "        generation_time = end_time - start_time\n",
    "        return response_text, generation_time\n",
    "    except Exception as e:\n",
    "        print(f\"Error running prompt on model '{model_name}': {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36c1bdc-df11-482d-a063-a8d8a519252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models to benchmark\n",
    "models_to_benchmark = [\"qwen2:0.5b\", \"qwen2:1.5b\", \"qwen2:7b\"]  # Adjust based on what you have/can run\n",
    "\n",
    "# The text to summarize (replace with any over several hundered word text)\n",
    "text_to_summarize = \"\"\"\n",
    "The study of artificial intelligence (AI) has grown exponentially in recent decades, moving from theoretical concepts to practical applications that impact various aspects of our lives. AI encompasses a wide range of technologies, including machine learning, natural language processing, computer vision, and robotics. Each of these subfields has witnessed significant advancements, leading to breakthroughs in areas such as healthcare, finance, transportation, and entertainment.\n",
    "Machine learning, a core component of AI, focuses on enabling computers to learn from data without being explicitly programmed. Algorithms like deep learning, a subset of machine learning with artificial neural networks having multiple layers, have achieved remarkable success in tasks like image recognition, speech recognition, and natural language understanding. These advancements have powered applications like virtual assistants, recommendation systems, and fraud detection tools.\n",
    "Natural language processing (NLP) deals with the interaction between computers and human language. NLP techniques enable computers to understand, interpret, and generate human language. This has led to the development of sophisticated chatbots, language translation services, and tools for sentiment analysis and text summarization. The ability of AI to process and understand human language is crucial for seamless human-computer interaction.\n",
    "Computer vision focuses on enabling computers to \"see\" and interpret visual information from the world. This field involves tasks like image classification, object detection, and facial recognition. Advances in computer vision have been instrumental in autonomous vehicles, medical imaging analysis, and security systems.\n",
    "Robotics, often integrated with AI technologies, involves the design, construction, operation, and application of robots. AI empowers robots to perform complex tasks autonomously, adapt to changing environments, and collaborate with humans. This has significant implications for manufacturing, logistics, and even personal assistance.\n",
    "The increasing availability of large datasets and powerful computing resources has been a major driving force behind the recent surge in AI capabilities. Cloud computing platforms provide access to vast computational power, allowing researchers and developers to train complex AI models. Furthermore, the open-source community has played a vital role in accelerating AI development by sharing tools, libraries, and pre-trained models.\n",
    "However, the rapid progress in AI also raises ethical and societal concerns. Issues such as bias in AI algorithms, the potential for job displacement due to automation, and the responsible use of AI technologies are subjects of ongoing debate and research. Addressing these challenges is crucial to ensure that AI benefits humanity as a whole.\n",
    "In conclusion, artificial intelligence is a transformative technology with the potential to reshape our world. Continued research, development, and thoughtful consideration of its ethical implications will be essential to harness its full potential and navigate its challenges effectively.\n",
    "\"\"\"\n",
    "\n",
    "# The prompt for summarization\n",
    "summarization_prompt = f\"Summarize the following text in about 100 words:\\n\\n{text_to_summarize}\"\n",
    "\n",
    "print(\"Starting benchmarking experiment...\")\n",
    "print(f\"Task: Summarize a {len(text_to_summarize.split())}-word text.\")\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_name in models_to_benchmark:\n",
    "    print(f\"\\n--- Benchmarking model: {model_name} ---\")\n",
    "    if pull_model_if_needed(model_name):\n",
    "        response, generation_time = run_and_time_prompt(model_name, summarization_prompt)\n",
    "        if response is not None and generation_time is not None:\n",
    "            print(f\"Response:\\n{response}\\n\")\n",
    "            print(f\"Generation Time: {generation_time:.2f} seconds\")\n",
    "            results[model_name] = {\"response\": response, \"time\": generation_time}\n",
    "        else:\n",
    "            results[model_name] = {\"response\": None, \"time\": None, \"error\": \"Prompt execution failed\"}\n",
    "    else:\n",
    "        results[model_name] = {\"response\": None, \"time\": None, \"error\": \"Model pull failed\"}\n",
    "\n",
    "print(\"\\n--- Benchmarking Results ---\")\n",
    "for model, data in results.items():\n",
    "    print(f\"Model: {model}\")\n",
    "    if \"error\" in data:\n",
    "        print(f\"  Error: {data['error']}\")\n",
    "    else:\n",
    "        print(f\"  Generation Time: {data['time']:.2f} seconds\")\n",
    "        print(\"  First 50 characters of Response:\", data['response'][:50] + \"...\")\n",
    "\n",
    "print(\"\\nObserve how the model size correlates with response time on your hardware.\")\n",
    "print(\"Manually assess the quality of the summaries to determine if the difference justifies the time.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c62a9e0-e3f1-45aa-88f6-e47a3f53dd9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
