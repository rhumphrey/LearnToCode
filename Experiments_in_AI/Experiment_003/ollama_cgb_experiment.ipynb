{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91afe4bb-d6da-4aaf-bad4-438c88420238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b71014e-984f-4a7c-8d18-c88644ee4bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_model_if_needed(model_name):\n",
    "    \"\"\"Pulls the specified model from Ollama if it doesn't exist.\"\"\"\n",
    "    try:\n",
    "        ollama.pull(model=model_name)\n",
    "        print(f\"Model '{model_name}' pulled successfully/already existed.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error pulling model '{model_name}': {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfe5241-b3b3-48bd-bb13-1d6a684fed24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_code_generation(model, prompt):\n",
    "    \"\"\"Asks the model to generate a piece of code.\"\"\"\n",
    "    print(f\"\\n--- Code Generation ---\\nPrompt: {prompt}\")\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=model,\n",
    "            messages=[{'role': 'user', 'content': prompt}]\n",
    "        )\n",
    "        code = response['message']['content'].strip()\n",
    "        print(f\"Generated Code:\\n{code}\\n\")\n",
    "        return code\n",
    "    except Exception as e:\n",
    "        print(f\"Error during code generation: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c8c06a-ce4b-479e-aa9e-019816aa949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_code_explanation(model, code_snippet):\n",
    "    \"\"\"Asks the model to explain a provided code snippet.\"\"\"\n",
    "    print(f\"\\n--- Code Explanation ---\\nCode Snippet:\\n{code_snippet}\")\n",
    "    prompt = f\"Explain the following Python code:\\n\\n{code_snippet}\"\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=model,\n",
    "            messages=[{'role': 'user', 'content': prompt}]\n",
    "        )\n",
    "        explanation = response['message']['content'].strip()\n",
    "        print(f\"Explanation:\\n{explanation}\\n\")\n",
    "        return explanation\n",
    "    except Exception as e:\n",
    "        print(f\"Error during code explanation: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7635339c-6669-4906-a931-9a54ffc27b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_code_translation(model, code_snippet, target_language):\n",
    "    \"\"\"Asks the model to translate a code snippet to another language.\"\"\"\n",
    "    print(f\"\\n--- Code Translation ---\\nOriginal Code (Python):\\n{code_snippet}\\nTarget Language: {target_language}\")\n",
    "    prompt = f\"Translate the following Python code to {target_language}:\\n\\n{code_snippet}\"\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=model,\n",
    "            messages=[{'role': 'user', 'content': prompt}]\n",
    "        )\n",
    "        translated_code = response['message']['content'].strip()\n",
    "        print(f\"Translated Code ({target_language}):\\n{translated_code}\")\n",
    "        return translated_code\n",
    "    except Exception as e:\n",
    "        print(f\"Error during code translation: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443e78f9-00f0-494e-836a-9805a30859ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_code_debugging(model, flawed_code):\n",
    "    \"\"\"Asks the model to find a bug in a flawed code snippet.\"\"\"\n",
    "    print(f\"\\n--- Code Debugging ---\\nFlawed Code:\\n{flawed_code}\")\n",
    "    prompt = f\"Find the bug in the following Python function and explain how to fix it:\\n\\n{flawed_code}\"\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model=model,\n",
    "            messages=[{'role': 'user', 'content': prompt}]\n",
    "        )\n",
    "        bug_report = response['message']['content'].strip()\n",
    "        print(f\"Bug Report:\\n{bug_report}\\n\")\n",
    "        return bug_report\n",
    "    except Exception as e:\n",
    "        print(f\"Error during code debugging: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be5a2a8-b02c-4fd1-95f7-639191cf6ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_model = \"codellama\"  # Also try \"codeqwen\", \"granite-code\", \"deepseek-coder\", \"codegemma\" or \"starcoder\"\n",
    "print(\"\\nStarting experiment...pulling any models as required...\\n\")\n",
    "try:\n",
    "    pull_model_if_needed(code_model)\n",
    "\n",
    "    # --- Experiment Prompts and Code ---\n",
    "    factorial_prompt = \"write a Python function to calculate the factorial of a number\"\n",
    "    code_to_explain = \"\"\"\n",
    "```\n",
    "def greet(name):\n",
    "    message = f\"Hello, {name}!\"\n",
    "    print(message)\n",
    "```\n",
    "    \"\"\"\n",
    "    code_to_translate = \"\"\"\n",
    "```\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "```\n",
    "    \"\"\"\n",
    "    flawed_code = \"\"\"\n",
    "```\n",
    "def calculate_average(numbers):\n",
    "    sum = 0\n",
    "    for number in numbers:\n",
    "        sum = sum + number\n",
    "    average = sum / len(numbers)\n",
    "    return average\n",
    "```\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Run the Experiments ---\n",
    "    generated_factorial_code = run_code_generation(code_model, factorial_prompt)\n",
    "    explanation = run_code_explanation(code_model, code_to_explain)\n",
    "    translated_code = run_code_translation(code_model, code_to_translate, \"JavaScript\")\n",
    "    bug_report = run_code_debugging(code_model, flawed_code)\n",
    "\n",
    "    print(\"\\n--- Experiment Observations ---\")\n",
    "    print(f\"Model Used: {code_model}\")\n",
    "    print(\"\\nCode Generation:\")\n",
    "    if generated_factorial_code:\n",
    "        # TODO You can add code here to try running the generated code and assess its accuracy\n",
    "        pass\n",
    "    print(\"\\nCode Explanation:\")\n",
    "    if explanation:\n",
    "        # TODO Assess the clarity and correctness of the explanation\n",
    "        pass\n",
    "    print(\"\\nCode Translation:\")\n",
    "    if translated_code:\n",
    "        # TODO Review the translated code for correctness and idiomatic JavaScript\n",
    "        pass\n",
    "    print(\"\\nCode Debugging:\")\n",
    "    if bug_report:\n",
    "        # TODO Evaluate if the bug was correctly identified and the fix is appropriate\n",
    "        pass\n",
    "\n",
    "    print(\"\\nRemember to manually observe the output to assess the model's performance based on the experiment criteria.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Exiting due to an error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57514026-7e17-4493-8988-1a1f30fb7147",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
